-시작
안녕하세요~ 1조 발표를 맡게된 김성민이라고 합니다.
저희가 다룰 데이터는 '강철'에 대한 데이터입니다.
-목차
발표의 순서로는, 첫번째로 분석배경 - 둘째로 데이터 분석과 목표
세번째로 머신러닝 모델의 수립과 적용이고 마지막으로 이에 대한 기대효과를 말씀드리겠습니다.

-분석배경 첫페이지
다들 어느정도 계시겠지만, 
'강철'은 단단한데다 탄력성이 좋아 일상의 거의 모든 부분에서 사용되고 있습니다.
그만큼 강철이 산업과 생활에 정말 중요하다는 의미로 첫 페이지를 제작하였습니다.

- 2페이지
20년 11월 기사를 가져왔습니다.
컴퓨터 통신기업 IBM의 대표 아빈드 크리슈나는 '데이터 챌린지'를 열었는데,
AI를 활용한 머신러닝을 철강 공정에 도입해 생산량을 늘릴 방안을 찾는 것이었습니다.
이는 바로 데이터를 활용하여 불량품을 잡아내는 방법과 동일합니다.

철강업에 지식이 전무한 데이터 전문가들이! 철강업계 전문가가 수십 년간 해결하지 못한 난제를 두 달 만에 풀어냈다는 내용을 담고 있습니다.
이처럼 앞으로 모든 기업들이 AI를 기반으로 손해를 막고, 이익을 극대화할 것이라 예측할 수 있습니다.

- 3페이지
저희가 데이터를 다룬 프로그램은 아나콘다3 주피터노트북 입니다!

- 4페이지
우선, steeldata를 불러오면 오른쪽 상단처럼 각 컬럼의 데이터 값을 볼 수 있습니다. 왼쪽의 표는 컬럼들을 보기좋게 정리한 것이고,
이 데이터 값들에서 저희는 SCALE 데이터 값. 양품/불량품의 발생빈도에 초점을 두었습니다.

- 5페이지
'작업시간' 그리고 '철강 종류'에 따라 데이터를 분석해 보겠습니다

- 6페이지
스텝1 '시간'별 양품과 불량품 갯수 측정
스텝2 '불량률' 계산을 위한 데이터 전처리
스텝3  1,2 규합 -> '시간'에 따른 '불량률' 측정

- 7페이지
롤링 데이터 컬럼을 이용하여 시간별 양품/불량품을 시각화 해보았습니다.
(자세한설명 -> 롤링데이터값을 데이트타임자료형변환 -> 시간만추출하여 정수형태로 변환)
여기서 파란 막대그래프가 '불량품'을 의미하는데, 그래프를 보시면 07시~12시까지 불량품의 갯수가 확연히 많을 것을 알 수 있습니다.

- 8페이지
다음으로 SCALE_NO 라는 컬럼을 만듭니다. 이컬럼의 데이터값은 양품이면 0, 불량품이면 1의 정수를 갖습니다.
막힘**

- 9페이지
시간만 추출한 데이터 값을 나누어 '새벽' '오전' '오후' '저녁' 설정하여 시간대를 더욱 간략화하였습니다.
이러면 더 보기 쉽죠?? 이리하여 최종적으로 '오전' 6~11시 사이에 불량품이 많이 나온 것을 확인하였습니다!
여기에서 저희는 외부적인 요인이 있을까하여 2008년 8월 1,2일의 날씨 데이터를 조사해봤지만!
해당 지역을 특정할 수 없었고, 오래전의 데이터여서 그런지 시간별 기온데이터를 찾는데 실패했습니다 ㅠㅠ

- 10페이지
이제 다음으로 '철강종류'에 포커스를 두어 '제품 별 생산율'을 도넛차트로 시각화 해보았습니다.
 도넛차트를 보시면 'C0'가 압도적으로 생산량이 많은걸 확인할 수 있습니다. 그다음으로는 'T8' 종류가 13% 정도로 많네요

- 11페이지
이번엔 불량품을 카운트하였고, 불량품 전체 갯수에서 각 종류의 비율을 계산해 보았습니다.
이건 뭐 종류 C0만 만든것 같네요 ㅎㅎ
 결국 저희는 C0가 불량품을 많이 생산한다는 것을 알게 되었고, C0의 불량품만 잡아도 전체의 불량품의 갯수가 적어질 것이란 걸 알았습니다.

- 12페이지
 상관계수 패스**

- 13페이지
 두 그래프는 x축과 y축이 같습니다. 가열로 추출온도와 내부에 있던 시간을 축으로 두었는데, 차이점은 C0의 데이터가 있고 없고 입니다.
 확실히 C0를 포함하면 불량품의 갯수가 월등히 많죠? 그리고 C0의 불량품은 가열로 온도가 1150도 이상, 추출시간이 275초 이상일때 많이 발생하는 것을 알아볼 수 있습니다.

- 14페이지
SZ가열로와 HZ가열로 시각화그래프입니다.**
SZ가열로는 1175도 이상일때 모두 불량
HZ가열로는 1200도 부터 모두 불량
이정도로만 알수 있습니다	

- 15페이지
 롤링 온도와 제작일자별 양품/불량품을 분석한 그래프입니다.
 C0종류가 불량품이 월등히 많고, 여기선 롤링 온도가 1000도 이상일 때 불량품이 많다는 것을 알 수 있습니다.

- 16페이지
 이제 머신러닝을 적용하는 단계입니다. 머신러닝 학습법에는 아시다시피 지도학습,비지도학습,강화학습 등이 있습니다.
 저희는 여기에서 양품과 불량품을 분류하는 지도학습법을 사용하였습니다.

- 17페이지
 Decision Tree는 우선 분류문제와 회귀문제 둘다 활용이 가능합니다. 활용범주가 넓고, 
최신 알고리즘의 기반모델이기 때문에 이것을 이해하고 쓰는 것이 중요하다고 할 수 있습니다.
 그림과 같이 기준을 두고 규칙들을 정해 분류하고 값을 예측하는 방법입니다.
이런식으로 분류를 하다보면 정확도가 올라가겠죠? 하지만! 깊이가 깊어질수록 복잡성이 높아져 예측률이 떨어지게 됩니다.. 이걸 오버피팅이라 하구요.

- 18페이지
target 소스코드 설명

- 19페이지

- 20페이지

- 21페이지
'앙상블' 이라는 단어는 조화,통일을 뜻합니다. 따라서 앙상블 모델은 여러 모델이 동일한 문제를 해결하고 더 좋은 결과를 얻도록 훈련시키는 모델이라 보시면 됩니다.
강사님이 좋아하시는 '집단지성' 단어가 떠오르는 모델이라 할 수 있습니다 ㅎ 과적합 감소효과를 갖고, 개별 모델 성능이 낮을 때 성능을 향상시킬 수 있는 모델이죠.
모델 종류에는 보팅,배깅,랜덤포레스트,그레디언트부스팅,스테킹 등이 있습니다.
이 중에서 저희는 앞서 결정트리의 깊이문제. 오버피팅의 문제를 최소화하기 위해 랜덤 포레스트와 그레디언트 부스팅 모델을 다루어봤습니다.

- 22페이지
 랜덤 포레스트는 말 그대로 여러개의 트리를 모아 숲을 만든 것과 같습니다. (의사결정나무를 배깅 알고리즘으로 구현한 모형)
한 번에 여러개의 트리를 형성하고 이것들을 독립적으로 병렬처리하여 트리들의 결과를 분류, 이 중 가장 성능이 좋은 것을 최종분류로 선택하는 것입니다.
생성한 일부 트리에서 오버피팅이 될 수 있지만 많은 트리를 생성함으로써 이를 방지할 수 있습니다.

- 23페이지
데이터 전처리시 '배깅'을 진행합니다. 배깅은 주머니에 공들을 넣고 일부분만 빼서 쓰는 느낌이죠?
따라서 랜덤포레스트의 각 트리는 Train 데이터의 일부분, 부분집합을 가지고 생성 및 학습됩니다. (데이터가 총 100개면 10개씩 사용)
이런 방식을 통해 다양한 트리가 만들어지고 오버피팅 문제를 해결하는 것이죠.
소스코드 설명**

- 24페이지
coefficient**

- 25페이지
그레디언트 부스팅 모델
깊이가 얕은 결정트리를 사용하고, 부스팅 알고리즘에 경사하강 알고리즘을 적용한 것입니다.
랜덤 포레스트와 비교하자면 조금 더 성능이 좋지만, 순서대로 트리를 추가해야 하기 때문에 속도가 느립니다.
부스팅 : 약한 학습기를 여러 개 결합해 강한 학습기를 만드는 기법
-> 여러 개의 모형을 순차적으로 학습하고 틀린 예측 데이터에 대해서 그 다음 모형이 순차적으로 학습해나가는 방식
-> 정확도가 낮더라도 일단 모형을 생성하고 이전 모형의 오류를 다음 모형에서 보완하는 과정을 반족하여 이들을 결합하는 방식
그레디언트 부스팅 : 이전 모형의 예측 오류를 보완하는 데 있어 약점을 손실함수로 나타내고 손실함수를 최소화하고자 경사하강법을 사용
-> 약한 학습기로서 주로 의사결정나무를 사용하게 되며 분류 및 수치 예측 모두에 사용가능

- 26페이지
소스 설명**

- 27페이지
coefficient

- 28페이지
각각의 모델 비교 설명

- 29페이지
기대효과


